#!/usr/bin/env python3
"""
StellarPulse / æ˜Ÿè„‰ - ç§‘æŠ€æƒ…æŠ¥ç›‘æ§ç³»ç»Ÿ v2.0
åŠŸèƒ½ï¼šå¤šæºé‡‡é›† + AIæ‘˜è¦ + å…³é”®è¯è®¢é˜… + Webç•Œé¢
"""

import json
import os
import sys
import argparse
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Dict, Any

# æ·»åŠ sourcesç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, '/home/ec2-user/stellarpulse/sources')

from rss import RSSSource
from hackernews import HackerNewsSource
from reddit import RedditSource
from arxiv import ArXivSource
from twitter import TwitterSource
from ai_summary import ContentAnalyzer
from subscription import SubscriptionManager

# ============ é…ç½® ============
CONFIG_FILE = "/home/ec2-user/stellarpulse/config.json"
DATA_FILE = "/home/ec2-user/stellarpulse/data.json"
REPORTS_DIR = "/home/ec2-user/stellarpulse/reports"

def load_config() -> Dict:
    """åŠ è½½é…ç½®"""
    with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
        return json.load(f)

def load_data() -> Dict:
    """åŠ è½½æ•°æ®"""
    if os.path.exists(DATA_FILE):
        try:
            with open(DATA_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            pass
    return {"items": [], "last_run": None, "stats": {}}

def save_data(data: Dict):
    """ä¿å­˜æ•°æ®"""
    with open(DATA_FILE, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

# ============ æ•°æ®æºé‡‡é›† ============
def collect_all(config: Dict) -> List[Dict]:
    """é‡‡é›†æ‰€æœ‰æ•°æ®æº"""
    all_items = []
    sources_config = config.get("sources", {})
    
    print(f"\n[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] å¼€å§‹é‡‡é›†...")
    
    # RSSæº
    for src_cfg in sources_config.get("rss", []):
        if src_cfg.get("enabled", True):
            print(f"  â†’ RSS: {src_cfg['name']}...", end=" ")
            source = RSSSource(src_cfg)
            items = source.fetch()
            all_items.extend(items)
            print(f"âœ“ {len(items)}æ¡")
    
    # APIæº
    for src_cfg in sources_config.get("api", []):
        if not src_cfg.get("enabled", True):
            continue
        
        source_type = src_cfg.get("type")
        print(f"  â†’ API: {src_cfg['name']}...", end=" ")
        
        if source_type == "hn":
            source = HackerNewsSource(src_cfg)
        elif source_type == "reddit":
            source = RedditSource(src_cfg)
        elif source_type == "arxiv":
            source = ArXivSource(src_cfg)
        elif source_type == "twitter":
            source = TwitterSource(src_cfg)
        else:
            print("âœ— æœªçŸ¥ç±»å‹")
            continue
        
        items = source.fetch()
        all_items.extend(items)
        print(f"âœ“ {len(items)}æ¡")
    
    print(f"  æ€»è®¡: {len(all_items)}æ¡")
    return all_items

# ============ å†…å®¹å¤„ç† ============
def classify_content(title: str, summary: str, config: Dict) -> List[str]:
    """å†…å®¹åˆ†ç±»"""
    text = (title + " " + summary).lower()
    categories = []
    
    for cat, keywords in config.get("keywords", {}).items():
        for kw in keywords:
            if kw.lower() in text:
                categories.append(cat)
                break
    
    return categories if categories else ["other"]

def process_items(items: List[Dict], config: Dict) -> List[Dict]:
    """å¤„ç†å†…å®¹ï¼šå»é‡ã€åˆ†ç±»ã€AIåˆ†æ"""
    print("\n[å¤„ç†å†…å®¹]")
    
    # å»é‡
    seen_links = set()
    unique_items = []
    for item in items:
        link = item.get("link", "")
        if link and link not in seen_links:
            seen_links.add(link)
            unique_items.append(item)
    
    print(f"  å»é‡å: {len(unique_items)}æ¡")
    
    # åˆ†ç±»å’Œåˆ†æ
    analyzer = ContentAnalyzer()
    processed = []
    
    for item in unique_items:
        # åˆ†ç±»
        categories = classify_content(
            item.get("title", ""), 
            item.get("summary", ""), 
            config
        )
        item["categories"] = categories
        
        # è·³è¿‡æ— å…³å†…å®¹
        if categories == ["other"]:
            continue
        
        # AIåˆ†æ
        analysis = analyzer.analyze(
            item.get("title", ""),
            item.get("summary", "")
        )
        item["ai_summary"] = analysis["summary"]
        item["keywords"] = analysis["keywords"]
        item["importance"] = analysis["importance"]
        
        processed.append(item)
    
    print(f"  ç›¸å…³èµ„è®¯: {len(processed)}æ¡")
    
    # æŒ‰é‡è¦æ€§æ’åº
    processed.sort(key=lambda x: x.get("importance", 0), reverse=True)
    
    return processed

# ============ æŠ¥å‘Šç”Ÿæˆ ============
def generate_report(items: List[Dict], config: Dict) -> tuple:
    """ç”ŸæˆæŠ¥å‘Š"""
    now = datetime.now()
    date_str = now.strftime("%Y-%m-%d")
    
    # æŒ‰åˆ†ç±»ç»„ç»‡
    by_cat = {"ai": [], "robotics": [], "space": []}
    for item in items:
        for cat in item.get("categories", []):
            if cat in by_cat:
                by_cat[cat].append(item)
    
    # ç”ŸæˆMarkdown
    per_cat = config.get("settings", {}).get("items_per_category", 15)
    
    md = f"""# ğŸ“¡ ç§‘æŠ€æƒ…æŠ¥æ—¥æŠ¥ | {date_str}

> ç”Ÿæˆæ—¶é—´: {now.strftime("%H:%M")}  
> æœ¬æœŸç²¾é€‰: {len(items)} æ¡ç›¸å…³èµ„è®¯ | AIè‡ªåŠ¨æ‘˜è¦

---

## ğŸ“Š æœ¬æœŸæ¦‚è§ˆ

| é¢†åŸŸ | æ•°é‡ | çƒ­é—¨å…³é”®è¯ |
|------|------|------------|
| ğŸ¤– AI | {len(by_cat['ai'])} | {get_top_keywords(by_cat['ai'])} |
| ğŸ¦¾ æœºå™¨äºº | {len(by_cat['robotics'])} | {get_top_keywords(by_cat['robotics'])} |
| ğŸš€ èˆªå¤© | {len(by_cat['space'])} | {get_top_keywords(by_cat['space'])} |

---

## ğŸ¤– AI & å¤§æ¨¡å‹ ({len(by_cat['ai'])} æ¡)

"""
    
    for item in by_cat["ai"][:per_cat]:
        md += format_item(item)
    
    md += f"""
## ğŸ¦¾ å…·èº«æ™ºèƒ½ & æœºå™¨äºº ({len(by_cat['robotics'])} æ¡)

"""
    for item in by_cat["robotics"][:per_cat]:
        md += format_item(item)
    
    md += f"""
## ğŸš€ èˆªå¤© & å¤ªç©º ({len(by_cat['space'])} æ¡)

"""
    for item in by_cat["space"][:per_cat]:
        md += format_item(item)
    
    md += """
---

*æœ¬æŠ¥å‘Šç”± StellarPulse è‡ªåŠ¨ç”Ÿæˆ*  
*Webç•Œé¢: http://your-server:8080*
"""
    
    # ä¿å­˜
    os.makedirs(REPORTS_DIR, exist_ok=True)
    report_path = f"{REPORTS_DIR}/report-{date_str}.md"
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(md)
    
    return report_path, md

def format_item(item: Dict) -> str:
    """æ ¼å¼åŒ–å•æ¡èµ„è®¯"""
    importance = item.get("importance", 0)
    stars = "â­" * int(importance)
    
    md = f"""### {item['title']} {stars}

- ğŸ”— [{item['link'][:60]}...]({item['link']})
- ğŸ“¡ {item['source']} | ğŸ• {item.get('fetched_at', '')[:16]}
"""
    
    if item.get("ai_summary"):
        md += f"- ğŸ“ AIæ‘˜è¦: {item['ai_summary']}\n"
    
    if item.get("keywords"):
        md += f"- ğŸ·ï¸ å…³é”®è¯: {', '.join(item['keywords'][:5])}\n"
    
    md += "\n"
    return md

def get_top_keywords(items: List[Dict]) -> str:
    """è·å–çƒ­é—¨å…³é”®è¯"""
    all_keywords = []
    for item in items[:5]:
        all_keywords.extend(item.get("keywords", []))
    
    # ç»Ÿè®¡é¢‘ç‡
    freq = {}
    for kw in all_keywords:
        freq[kw] = freq.get(kw, 0) + 1
    
    top = sorted(freq.items(), key=lambda x: x[1], reverse=True)[:3]
    return ', '.join([k[0] for k in top]) if top else 'N/A'

# ============ å…³é”®è¯è®¢é˜…æ£€æŸ¥ ============
def check_subscriptions(items: List[Dict]) -> List[Dict]:
    """æ£€æŸ¥å…³é”®è¯åŒ¹é…"""
    mgr = SubscriptionManager()
    matches = mgr.check_matches(items)
    
    if matches:
        print(f"\n[å…³é”®è¯è®¢é˜…] å‘ç° {len(matches)} æ¡åŒ¹é…")
        for m in matches[:5]:
            print(f"  ğŸ”” {m['subscription']['keyword']}: {m['item']['title'][:50]}...")
    
    return matches

# ============ WhatsAppæ‘˜è¦ ============
def generate_whatsapp_summary(items: List[Dict], matches: List[Dict]) -> str:
    """ç”ŸæˆWhatsAppæ¨é€æ‘˜è¦"""
    now = datetime.now().strftime("%m-%d %H:%M")
    
    # ç»Ÿè®¡
    counts = {"ai": 0, "robotics": 0, "space": 0}
    for item in items:
        for cat in item.get("categories", []):
            if cat in counts:
                counts[cat] += 1
    
    # å–Top 3æ ‡é¢˜
    top_items = items[:3]
    
    msg = f"""ğŸ“¡ StellarPulse æ—¥æŠ¥ {now}

ğŸ¤– AI: {counts['ai']} | ğŸ¦¾ æœºå™¨äºº: {counts['robotics']} | ğŸš€ èˆªå¤©: {counts['space']}

ğŸ”¥ çƒ­é—¨èµ„è®¯:
"""
    for i, item in enumerate(top_items, 1):
        title = item['title'][:35] + "..." if len(item['title']) > 35 else item['title']
        msg += f"{i}. {title}\n"
    
    if matches:
        msg += f"\nğŸ”” å…³é”®è¯å‘½ä¸­: {len(matches)}æ¡\n"
    
    msg += "\nğŸ“„ å®Œæ•´æŠ¥å‘Šå·²ç”Ÿæˆ\nğŸŒ Web: http://your-server:8080"
    
    return msg

# ============ ä¸»æµç¨‹ ============
def main():
    parser = argparse.ArgumentParser(description='StellarPulse')
    parser.add_argument('--web', action='store_true', help='å¯åŠ¨WebæœåŠ¡å™¨')
    parser.add_argument('--subscribe', type=str, help='æ·»åŠ å…³é”®è¯è®¢é˜…')
    parser.add_argument('--list-subs', action='store_true', help='åˆ—å‡ºè®¢é˜…')
    args = parser.parse_args()
    
    # WebæœåŠ¡å™¨æ¨¡å¼
    if args.web:
        from web.server import start_server
        config = load_config()
        port = config.get("settings", {}).get("web_port", 8080)
        start_server(port)
        return
    
    # è®¢é˜…ç®¡ç†
    if args.subscribe:
        mgr = SubscriptionManager()
        sub = mgr.add_subscription(args.subscribe)
        print(f"âœ… å·²æ·»åŠ è®¢é˜…: {args.subscribe} (ID: {sub['id']})")
        return
    
    if args.list_subs:
        mgr = SubscriptionManager()
        subs = mgr.list_subscriptions()
        print(f"ğŸ”” å½“å‰è®¢é˜… ({len(subs)}ä¸ª):")
        for s in subs:
            print(f"  â€¢ {s['keyword']} (åŒ¹é…: {s.get('match_count', 0)}æ¬¡)")
        return
    
    # æ­£å¸¸é‡‡é›†æ¨¡å¼
    print("=" * 60)
    print("ğŸ“¡ StellarPulse v2.0 å¯åŠ¨")
    print("=" * 60)
    
    # åŠ è½½é…ç½®
    config = load_config()
    data = load_data()
    
    # 1. é‡‡é›†
    raw_items = collect_all(config)
    
    # 2. å¤„ç†
    processed = process_items(raw_items, config)
    
    # 3. å»é‡ (ä¸å†å²æ•°æ®)
    existing_links = {item["link"] for item in data.get("items", [])}
    new_items = [item for item in processed if item["link"] not in existing_links]
    print(f"\n[æ•°æ®æ›´æ–°] æ–°å¢: {len(new_items)}æ¡")
    
    # 4. ä¿å­˜
    data["items"] = (data.get("items", []) + new_items)[-1000:]  # ä¿ç•™1000æ¡
    data["last_run"] = datetime.now().isoformat()
    data["stats"] = {
        "total_items": len(data["items"]),
        "last_new_items": len(new_items),
        "last_run": datetime.now().isoformat()
    }
    save_data(data)
    
    # 5. æ£€æŸ¥è®¢é˜…
    matches = check_subscriptions(new_items)
    
    # 6. ç”ŸæˆæŠ¥å‘Š
    if processed:
        report_path, full_report = generate_report(processed, config)
        print(f"\n[æŠ¥å‘Šç”Ÿæˆ] {report_path}")
        
        # 7. WhatsAppæ‘˜è¦
        whatsapp_msg = generate_whatsapp_summary(processed, matches)
        print("\n" + "=" * 60)
        print("WHATSAPP_MSG_START")
        print(whatsapp_msg)
        print("WHATSAPP_MSG_END")
    else:
        print("\n[æŠ¥å‘Š] æœ¬æœŸæ— ç›¸å…³èµ„è®¯")
    
    print("=" * 60)
    print("âœ… å®Œæˆ")

if __name__ == "__main__":
    main()
